{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","execution_count":null,"source":["#y_ This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import librosa\n","from sklearn.model_selection import train_test_split\n","import datetime as dt\n","import tensorflow as tf\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\n","X_data = []\n","y_data = []\n","\n","sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"],"outputs":[],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-28T19:49:17.02754Z","iopub.execute_input":"2021-07-28T19:49:17.027944Z","iopub.status.idle":"2021-07-28T20:19:31.332941Z","shell.execute_reply.started":"2021-07-28T19:49:17.02786Z","shell.execute_reply":"2021-07-28T20:19:31.331936Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["label = -2\n","for dirname, _, filenames in os.walk('/kaggle/input/audio-emotions/Emotions/'):\n","    label +=1\n","    print(f\"Emotion:{dirname}, Class:{label}\")\n","    for filename in filenames:\n","#         print(os.path.join(dirname, filename))\n","        y, sr = librosa.load(os.path.join(dirname, filename))\n","        mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T,axis=0)\n","        X_data.append(mfccs)\n","        y_data.append(int(label)) \n","\n","print(X_data[:5])\n","print(y_data[:5])\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["np.save('X_data.npy', X_data)\n","np.save('y_data.npy', y_data)\n","!ls -1"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["X_data = load('X_data.npy')\n","y_data = load('y_data.npy')"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["NUM_OF_CLASSES = 8\n","NUM_OF_ACTORS = 24"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:20:31.515249Z","iopub.execute_input":"2021-07-28T20:20:31.515573Z","iopub.status.idle":"2021-07-28T20:20:31.519093Z","shell.execute_reply.started":"2021-07-28T20:20:31.51554Z","shell.execute_reply":"2021-07-28T20:20:31.518251Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["ravdess_speech_data_array = np.asarray(X_data)\n","y_data_array = np.array(y_data)\n","print(y_data_array.shape)\n","labels_categorical = tf.keras.utils.to_categorical(y_data_array)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:21:11.585919Z","iopub.execute_input":"2021-07-28T20:21:11.586267Z","iopub.status.idle":"2021-07-28T20:21:11.60319Z","shell.execute_reply.started":"2021-07-28T20:21:11.586238Z","shell.execute_reply":"2021-07-28T20:21:11.602331Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import tensorflow as tf\n","\n","inputs = tf.keras.Input(shape=(1, 40))\n","\n","x = tf.keras.layers.Dense(64, activation='relu') (inputs)\n","x = tf.keras.layers.Dense(128, activation='relu') (x)\n","x = tf.keras.layers.Dropout(rate = 0.2)(x)\n","x =tf.keras.layers.LSTM(128, return_sequences=True)(x)\n","x =tf.keras.layers.LSTM(128, return_sequences=True)(x)\n","x = tf.keras.layers.Dense(128, activation='relu') (x)\n","x = tf.keras.layers.Dense(128, activation='relu') (x)\n","x = tf.keras.layers.Dropout(rate = 0.2)(x)\n","\n","outputs = tf.keras.layers.Dense(7, activation='softmax')(x)\n","\n","res_model = tf.keras.Model(inputs, outputs)\n","\n","res_model.compile(optimizer=tf.keras.optimizers.Adam(),\n","              loss='categorical_crossentropy',\n","              metrics=['acc'])\n","\n","print(res_model.summary())"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:56:54.644688Z","iopub.execute_input":"2021-07-28T20:56:54.64503Z","iopub.status.idle":"2021-07-28T20:56:55.242366Z","shell.execute_reply.started":"2021-07-28T20:56:54.645002Z","shell.execute_reply":"2021-07-28T20:56:55.241587Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["x_train,x_test,y_train,y_test= train_test_split(np.array(ravdess_speech_data_array),labels_categorical, test_size=0.20, random_state=9, shuffle=True)\n","x_train,x_val,y_train,y_val= train_test_split(x_train, y_train, test_size=0.20, random_state=9, shuffle=True)\n","callbacks = [\n","  # Write TensorBoard logs to `./logs` directory\n","  tf.keras.callbacks.TensorBoard(log_dir='./log/{}'.format(dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")), write_images=True),\n","]\n","\n","# # df_train.drop([\"class\"], axis=1)\n","history = res_model.fit(np.expand_dims(x_train, 1), np.expand_dims(y_train, 1), epochs=256, batch_size=256,\n","          validation_data=(np.expand_dims(x_val, 1), np.expand_dims(y_val, 1)), callbacks=callbacks)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:57:05.377765Z","iopub.execute_input":"2021-07-28T20:57:05.378186Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["print(\"Evaluate on test data\")\n","results = res_model.evaluate(np.expand_dims(x_test, 1), y_test, batch_size=256)\n","print(\"test loss, test acc:\", results)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:28:44.300619Z","iopub.execute_input":"2021-07-28T20:28:44.301035Z","iopub.status.idle":"2021-07-28T20:28:44.386389Z","shell.execute_reply.started":"2021-07-28T20:28:44.301Z","shell.execute_reply":"2021-07-28T20:28:44.385234Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","# import Image\n","\n","print(history.history.keys())\n","#  \"Accuracy\"\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(\"accuracy.jpg\")\n","\n","plt.show()\n","# \"Loss\"\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.savefig(\"loss.jpg\")\n","\n","plt.show()\n"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-07-28T20:39:48.245984Z","iopub.execute_input":"2021-07-28T20:39:48.246363Z","iopub.status.idle":"2021-07-28T20:39:48.667415Z","shell.execute_reply.started":"2021-07-28T20:39:48.246332Z","shell.execute_reply":"2021-07-28T20:39:48.666413Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}